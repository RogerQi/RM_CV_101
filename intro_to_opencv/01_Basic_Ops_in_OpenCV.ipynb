{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Just like how NumPy is popular for scientific computation practitioners, OpenCV is the most popular package for computer vision, especially traditional computer vision.\n",
    "\n",
    "In this notebook, we will teach you about basic operations in OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OpenCV!\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image\n",
    "\n",
    "First thing first, we need to load an image using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./imgs/bulbs_in_room.jpg')\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the output of the above cell, you can tell that OpenCV images are nothing more than NumPy array! The underlying type of these images are NumPy arrays. Why? Recall from the last module that images are represented as array of shape (height, width, channels). We can verify that by running: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, C = img.shape\n",
    "print(\"My height is: {0}; width is: {1}; number of channel is: {2}\".format(H, W, C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now, remember how we visualized the NumPy array from last module by calling the *plt.imshow* function? we can do the same thing to see what the image looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait... There is something wrong with the image! The path to the image can be found here [./imgs/bulbs_in_room.jpg](./imgs/bulbs_in_room.jpg). What went wrong?\n",
    "\n",
    "Remember that I told you the channels of images are arranged in RGB? A natural question to be asked here is why does it have to be RGB? Can it be BGR/GRB/GBR etc? The answer is yes. Actually, for some historical reasons, image representations in OpenCV are done in **BGR instead of RGB**.\n",
    "\n",
    "Therefore, to correctly visualize this image, we need to use another function in OpenCV called *cv2.cvtColor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert color image to grayscale image\n",
    "\n",
    "It's possible to do a lot of interesting things with *cv2.cvtColor*. One useful case is to convert color image to grayscale. If you are keen on observing things, you may notice that the second parameter in *cv2.cvtColor* seems to be interesting.\n",
    "\n",
    "I can tell you that the answer is *cv2.COLOR_BGR2GRAY*. But in the future, when you need to do conversion, you should always look up OpenCV documentation at https://docs.opencv.org/master/d8/d01/group__imgproc__color__conversions.html#ga4e0972be5de079fed4e3a10e24ef5ef0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "print(type(img_gray))\n",
    "print(img_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the type of the variable remains to be *np.array*. However, the shape of the image has changed from $(694, 1166, 3)$ to $(694, 1166)$! That's because grayscale image only comes with a **single grayscale channel**, where a value of $0$ means a pixel is completely black. While a value of $255$ usually means a pixel is completely white.\n",
    "\n",
    "We may perform some visualization here to get a sense of how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must explicitly tell pyplot that it's a grayscale image\n",
    "# so we attach a 'cmap' parameter\n",
    "plt.imshow(img_gray, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Computer Vision Task: Find All Light Bulbs in This Image \n",
    "\n",
    "Suppose you are working as a summer computer vision intern at Hopeless AI Inc. One day, the CEO from No Hope Home Improvement Inc., **Alvin the Mechanical Guy**, came in and asked for help. He has decorated a room with several light bulbs but some of them aren't working. Desperate for help, he wants a computer vision algorithm that is capable of detecting all the working light bulbs, while leaving out the malfunctioning one.\n",
    "\n",
    "Your supervisor, **His Grace, the Awesome Roger**, has assigned you a task to find the locations of all **functioning** light bulbs in a given RGB image.\n",
    "\n",
    "Don't panic. In this example task, I will walk you through the old-school workflow to design a traditional computer vision algorithm to solve this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The standard procedure to design a computer vision algorithm with examples:\n",
    "    \n",
    "1. Think about the physical properties of objects of interest (more formally and professionally, we call these objects 'foreground'). What property distinguishes it from the background environment?\n",
    "    - I need to design an algorithm to find all the working light bulbs.\n",
    "    - Unlike the malfunctioning ones or the environment, working light bulbs are **bright**.\n",
    "2. If you find any interesting property, can you describe it in formal language of OpenCV?\n",
    "    - In grayscale image, if a pixel is brighter than surrounding pixels, then it means the value of this pixel is closer to 255 than other pixels.\n",
    "    - We can use some sort of **hard cutoff** to differentiate bright pixels and dark pixels.\n",
    "3. Implement and inspect the output of your algorithm visually. You may need to go back and adjust some numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's begin to design our algorithm. Recall that the value of RGB fall into the range of $[0, 255]$. To start with, we choose $150$ as our **hard cutoff of brightness**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_cutoff = 150\n",
    "\n",
    "# Let's assume that we are given the 'img' variable\n",
    "# 1. Convert it to grayscale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# 2. Apply hard cut off\n",
    "# Hint 1: Recall that images loaded by OpenCV are stored as NumPy arrays\n",
    "# Hint 2: recall logical operations and binarization tricks back in the NumPy module\n",
    "#           (in case you have forgotten these, you can always go back and review)\n",
    "img_binarized = (img_gray > hard_cutoff)\n",
    "# 3. Scale for display purpose\n",
    "img_show = (img_binarized * 255)\n",
    "# 4. Visually inspect our result\n",
    "plt.imshow(img_show, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback from the result\n",
    "\n",
    "Well, this looks promising. But some reflections from the malfunctioning light bulbs are captured in this image as well. Therefore, to make sure malfunctioning light bulbs are eliminated, we can **increase the cutoff**.\n",
    "\n",
    "For simplicity, we will simply copy and paste the code trunk from the cell and change the *hard_cutoff* value. However do note that copying and pasting is a very bad practice in team projects and is not encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_cutoff = 252\n",
    "\n",
    "# Let's assume that we are given the 'img' variable\n",
    "# 1. Convert it to grayscale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# 2. Apply hard cut off\n",
    "# Hint 1: Recall that images loaded by OpenCV are stored as NumPy arrays\n",
    "# Hint 2: recall logical operations and binarization tricks back in the NumPy module\n",
    "#           (in case you have forgotten these, you can always go back and review)\n",
    "img_binarized = (img_gray > hard_cutoff)\n",
    "# 3. Scale for display purpose\n",
    "img_show = (img_binarized * 255)\n",
    "# 4. Visually inspect our result\n",
    "plt.imshow(img_show, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good now! Congrats to you making your first step at Hopeless AI Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP1.1\n",
    "\n",
    "Hopeless AI Inc. has announced that they will be joining the RoboMaster Internation Competition next year! Your supervisor, pleased by your result of your project with No Hope Home Improvement Inc, assigned you a new task.\n",
    "\n",
    "Your task, should you choose to accept it, is to detect the blue light bar on this piece of RoboMaster armor board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./imgs/rm_blue_armor_board_no_digit.jpg')\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MP1.2\n",
    "\n",
    "Think about the limitation of this old-school approach.\n",
    "- Recall that in step 1 of our designing process, we need to come up with some assumptions that may help us differentiate the foreground from the background.\n",
    "- However, is that always possible?\n",
    "\n",
    "To illustrate such limitation, use your approach from MP1.1 to locate the blur light bar of the armor board in this image. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./imgs/rm_robot.jpg')\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
